{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Theory: A Unified Framework\n",
    "\n",
    "This notebook provides a practical introduction to Prompt Theory, a unified framework for understanding and optimizing prompts across both AI systems and human cognition. \n",
    "\n",
    "By working through this tutorial, you'll gain hands-on experience with:\n",
    "1. The core principles of Prompt Theory\n",
    "2. Applying the mathematical framework to real-world examples\n",
    "3. Optimizing prompts using cognitive science principles\n",
    "4. Measuring and analyzing prompt effectiveness\n",
    "5. Detecting emergent behavior in recursive systems\n",
    "\n",
    "## What is Prompt Theory?\n",
    "\n",
    "Prompt Theory establishes a formal framework for understanding the structural isomorphisms between AI prompting systems and human neurobiological input-output mechanisms. By analyzing these parallel processes, we can develop more effective prompts for both AI systems and human cognition.\n",
    "\n",
    "The framework consists of three core components:\n",
    "- **Attention Allocation**: How systems focus on relevant information\n",
    "- **Recursive Processing**: How systems process information through multiple layers\n",
    "- **Drift Management**: How systems maintain stability while adapting\n",
    "\n",
    "Let's begin by installing the prompt-theory package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install prompt-theory package\n",
    "!pip install prompt-theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import core modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "from prompt_theory import PromptOptimizer\n",
    "from prompt_theory.models import AttentionModel, RecursiveProcessor, DriftModel\n",
    "from prompt_theory.evaluation import PromptEffectivenessEvaluator\n",
    "from prompt_theory.evaluation import EmergenceDetector\n",
    "from prompt_theory.optimizers import NeurobiologicalOptimizer\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Attention Allocation\n",
    "\n",
    "Attention allocation is a core component of Prompt Theory. It models how both AI systems and human cognition allocate limited attention resources across available information.\n",
    "\n",
    "The AttentionModel class implements the mathematical framework for attention allocation defined in Equation (5) of the Prompt Theory paper:\n",
    "\n",
    "$$A(X) = \\text{softmax}(Q(X) \\cdot K(X)^T / \\sqrt{d})$$\n",
    "\n",
    "With modifications for recency and salience as defined in Equation (6):\n",
    "\n",
    "$$A'(X) = \\lambda \\cdot A(X) + (1-\\lambda) \\cdot R(X)$$\n",
    "\n",
    "Let's see how this works in practice with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize attention model\n",
    "attention_model = AttentionModel(\n",
    "    capacity=7,  # Working memory-inspired capacity limit\n",
    "    recency_bias=0.3,  # Weight for recency effects\n",
    "    salience_weight=0.5  # Weight for salience factors\n",
    ")\n",
    "\n",
    "# Define a simple context with elements\n",
    "context = [\n",
    "    \"Artificial intelligence is transforming many industries.\",\n",
    "    \"Large language models are trained on vast text corpora.\",\n",
    "    \"Prompt engineering is the practice of designing effective prompts for AI systems.\",\n",
    "    \"Attention mechanisms allow models to focus on relevant parts of the input.\",\n",
    "    \"Recursive processing enables handling of complex nested structures.\",\n",
    "    \"Drift occurs when a system gradually shifts away from its intended behavior.\",\n",
    "    \"Emergence refers to the appearance of properties not predictable from components.\",\n",
    "    \"Neurobiological principles can inform AI system design.\",\n",
    "    \"Working memory is limited in capacity, typically to 7Â±2 items.\"\n",
    "]\n",
    "\n",
    "# Define salience factors (importance of each element)\n",
    "salience_factors = {\n",
    "    0: 0.5,  # General background\n",
    "    1: 0.6,  # General background\n",
    "    2: 0.9,  # Highly relevant to prompt engineering\n",
    "    3: 0.8,  # Relevant to attention mechanisms\n",
    "    4: 0.7,  # Relevant to recursive processing\n",
    "    5: 0.7,  # Relevant to drift\n",
    "    6: 0.8,  # Relevant to emergence\n",
    "    7: 0.9,  # Relevant to the neurobiological connection\n",
    "    8: 0.7   # Relevant to working memory\n",
    "}\n",
    "\n",
    "# Define recency (most recent items first)\n",
    "recency_indices = [8, 7, 6, 5, 4, 3, 2, 1, 0]  # Assuming items 8, 7, 6 were seen most recently\n",
    "\n",
    "# Allocate attention across context elements\n",
    "attention_allocation = attention_model.allocate(\n",
    "    context=context,\n",
    "    salience_factors=salience_factors,\n",
    "    recency_indices=recency_indices\n",
    ")\n",
    "\n",
    "# Display attention allocation\n",
    "for i, (element, attention) in enumerate(sorted(attention_allocation.items(), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"Element {i}: {attention:.4f} - {context[i][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize attention allocation\n",
    "plt.figure(figsize=(12, 6))\n",
    "indices = list(attention_allocation.keys())\n",
    "values = [attention_allocation[i] for i in indices]\n",
    "\n",
    "# Create shortened labels\n",
    "labels = [f\"{i}: {context[i][:30]}...\" for i in indices]\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "plt.barh(labels, values, color=sns.color_palette(\"viridis\", len(indices)))\n",
    "plt.xlabel('Attention Allocation')\n",
    "plt.ylabel('Context Elements')\n",
    "plt.title('Attention Allocation Across Context Elements')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Attention Patterns\n",
    "\n",
    "The visualization above shows how attention is distributed across the context elements based on their salience and recency. Notice that elements with high salience (relevance) and high recency receive more attention, modeling how both AI systems and human cognition prioritize information.\n",
    "\n",
    "In both domains, attention is a limited resource that must be allocated efficiently. The AttentionModel implements this constraint through the capacity parameter, which suppresses attention to less important elements when there are too many items to process.\n",
    "\n",
    "Now, let's see how we can optimize a context to focus attention on specific key elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify key elements we want to focus attention on\n",
    "key_elements = [2, 3, 7]  # Prompt engineering, attention mechanisms, and neurobiological principles\n",
    "\n",
    "# Optimize context to focus attention on these key elements\n",
    "optimized_context = attention_model.optimize_for_focus(\n",
    "    context=context,\n",
    "    target_elements=key_elements\n",
    ")\n",
    "\n",
    "# Allocate attention on the optimized context\n",
    "optimized_allocation = attention_model.allocate(\n",
    "    context=optimized_context,\n",
    "    salience_factors={i: salience_factors[optimized_context.index(context[i])] if context[i] in optimized_context else 0.5 \n",
    "                     for i in range(len(context))},\n",
    "    recency_indices=list(range(len(optimized_context)))[::-1]  # Most recent last\n",
    ")\n",
    "\n",
    "# Display optimized context\n",
    "print(\"Optimized Context:\")\n",
    "for i, element in enumerate(optimized_context):\n",
    "    print(f\"{i}: {element[:50]}...\")\n",
    "\n",
    "# Display target element attention\n",
    "print(\"\\nAttention on Target Elements:\")\n",
    "target_indices = [optimized_context.index(context[i]) for i in key_elements if context[i] in optimized_context]\n",
    "target_attention = sum(optimized_allocation.get(i, 0) for i in target_indices)\n",
    "print(f\"Total attention on target elements: {target_attention:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Recursive Processing\n",
    "\n",
    "Recursive processing is another core component of Prompt Theory. It models how systems process information through multiple layers of abstraction, and how emergence and collapse can occur during this process.\n",
    "\n",
    "The RecursiveProcessor class implements this framework, focusing on the conditions under which new properties emerge or the system becomes unstable.\n",
    "\n",
    "Let's explore a simple example of recursive processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize recursive processor\n",
    "recursive_processor = RecursiveProcessor(\n",
    "    max_depth=4,  # Maximum recursion depth\n",
    "    collapse_threshold=0.8,  # Threshold for recursive collapse\n",
    "    emergence_threshold=0.6  # Threshold for emergence\n",
    ")\n",
    "\n",
    "# Define a simple recursive processing function\n",
    "def process_recursively(state):\n",
    "    # Extract current values\n",
    "    depth = state.get(\"_depth\", 0)\n",
    "    complexity = state.get(\"complexity\", 0.2)\n",
    "    integration = state.get(\"integration\", 0.1)\n",
    "    coherence = state.get(\"coherence\", 0.9)\n",
    "    \n",
    "    # Update state based on recursive processing\n",
    "    new_state = state.copy()\n",
    "    \n",
    "    # Increase complexity with depth\n",
    "    new_state[\"complexity\"] = complexity + (0.2 * depth)\n",
    "    \n",
    "    # Increase integration (potential for emergence)\n",
    "    new_state[\"integration\"] = integration + (0.15 * depth)\n",
    "    \n",
    "    # Decrease coherence (potential for collapse) if complexity too high\n",
    "    if new_state[\"complexity\"] > 0.7:\n",
    "        new_state[\"coherence\"] = coherence - (0.1 * (new_state[\"complexity\"] - 0.7))\n",
    "    \n",
    "    # Add output at each step\n",
    "    new_state[\"_output\"] = f\"Processed at depth {depth} with complexity={new_state['complexity']:.2f}, integration={new_state['integration']:.2f}, coherence={new_state['coherence']:.2f}\"\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "# Process input recursively\n",
    "result = recursive_processor.process(\n",
    "    input_data={\"initial_data\": \"test\"},\n",
    "    processing_function=process_recursively,\n",
    "    max_iterations=10,\n",
    "    trace_execution=True\n",
    ")\n",
    "\n",
    "# Display recursive processing results\n",
    "print(\"Recursive Processing Results:\")\n",
    "print(f\"Final Output: {result['output']}\")\n",
    "print(f\"Iterations: {result['iterations']}\")\n",
    "print(f\"Depth: {result['depth']}\")\n",
    "print(f\"Converged: {result['converged']}\")\n",
    "print(f\"Stability: {result['stability']:.4f}\")\n",
    "print(f\"Emergence Detected: {result['emergence_detected']}\")\n",
    "print(f\"Collapse Detected: {result['collapse_detected']}\")\n",
    "\n",
    "# Display execution trace\n",
    "print(\"\\nExecution Trace:\")\n",
    "for i, trace_step in enumerate(result.get(\"execution_trace\", [])):\n",
    "    print(f\"Step {i}:\")\n",
    "    print(f\"  Depth: {trace_step['depth']}\")\n",
    "    print(f\"  System State: {trace_step['system_state']}\")\n",
    "    print(f\"  Discontinuity: {trace_step['discontinuity']:.4f}\")\n",
    "    print(f\"  Integration: {trace_step['integration']:.4f}\")\n",
    "    print(f\"  State: {trace_step['system_state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize recursive processing trajectory\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Extract data from execution trace\n",
    "depths = [step['depth'] for step in result.get(\"execution_trace\", [])]\n",
    "complexity = [step['state_snapshot'].get('complexity', 0) for step in result.get(\"execution_trace\", [])]\n",
    "integration = [step['integration'] for step in result.get(\"execution_trace\", [])]\n",
    "coherence = [step['state_snapshot'].get('coherence', 0) for step in result.get(\"execution_trace\", [])]\n",
    "discontinuity = [step['discontinuity'] for step in result.get(\"execution_trace\", [])]\n",
    "\n",
    "# Plot metrics\n",
    "plt.plot(depths, complexity, 'o-', label='Complexity', color='blue')\n",
    "plt.plot(depths, integration, 's-', label='Integration', color='green')\n",
    "plt.plot(depths, coherence, '^-', label='Coherence', color='purple')\n",
    "plt.plot(depths, discontinuity, 'x-', label='Discontinuity', color='red')\n",
    "\n",
    "# Add threshold lines\n",
    "plt.axhline(y=recursive_processor.parameters.emergence_threshold, \n",
    "           linestyle='--', color='green', alpha=0.7, label='Emergence Threshold')\n",
    "plt.axhline(y=recursive_processor.parameters.collapse_threshold, \n",
    "           linestyle='--', color='red', alpha=0.7, label='Collapse Threshold')\n",
    "\n",
    "plt.xlabel('Recursion Depth')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Recursive Processing Trajectory')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Recursive Processing\n",
    "\n",
    "The visualization above shows the trajectory of recursive processing. As recursion depth increases:\n",
    "\n",
    "1. **Complexity** increases, modeling the growing complexity of representations\n",
    "2. **Integration** increases, potentially leading to emergence when it exceeds the emergence threshold\n",
    "3. **Coherence** decreases as complexity increases, potentially leading to collapse when discontinuity exceeds the collapse threshold\n",
    "\n",
    "This models how both AI and human cognitive systems can develop emergent properties through recursive processing, but also risk collapse if the processing becomes too complex or incoherent.\n",
    "\n",
    "Now, let's simulate multiple recursive processing runs to analyze stability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate multiple recursive processing runs with varying noise\n",
    "simulation_results = recursive_processor.simulate_recursion(\n",
    "    input_data={\"initial_data\": \"test\"},\n",
    "    processing_function=process_recursively,\n",
    "    num_simulations=10,\n",
    "    noise_level=0.1\n",
    ")\n",
    "\n",
    "# Display simulation results\n",
    "print(\"Simulation Results:\")\n",
    "print(f\"Number of Simulations: {simulation_results['num_simulations']}\")\n",
    "print(f\"Noise Level: {simulation_results['noise_level']}\")\n",
    "print(f\"Collapse Rate: {simulation_results['collapse_rate']:.4f}\")\n",
    "print(f\"Emergence Rate: {simulation_results['emergence_rate']:.4f}\")\n",
    "print(f\"Convergence Rate: {simulation_results['convergence_rate']:.4f}\")\n",
    "print(f\"Average Iterations: {simulation_results['avg_iterations']:.2f}\")\n",
    "print(f\"Average Depth: {simulation_results['avg_depth']:.2f}\")\n",
    "print(f\"Average Stability: {simulation_results['avg_stability']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Managing Drift and Stability\n",
    "\n",
    "The third core component of Prompt Theory is drift management. It models how systems change over time and how to maintain stability while allowing for adaptation.\n",
    "\n",
    "The DriftModel class implements this framework, providing tools for measuring, predicting, and managing drift in system behavior.\n",
    "\n",
    "Let's explore a simple example of drift analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize drift model\n",
    "drift_model = DriftModel(\n",
    "    stability_params={\"anchoring_weight\": 0.7},\n",
    "    drift_detection_threshold=0.3\n",
    ")\n",
    "\n",
    "# Create a simple state history with gradually increasing drift\n",
    "state_history = [\n",
    "    {\"content\": \"Original prompt: Explain how neural networks function.\",\n",
    "     \"vector\": [0.1, 0.2, 0.3, 0.4]},\n",
    "    {\"content\": \"Modified prompt: Explain how neural networks learn from data.\",\n",
    "     \"vector\": [0.15, 0.25, 0.3, 0.4]},\n",
    "    {\"content\": \"Modified prompt: Describe neural network training and learning algorithms.\",\n",
    "     \"vector\": [0.2, 0.3, 0.35, 0.45]},\n",
    "    {\"content\": \"Modified prompt: Explain backpropagation and gradient descent in neural networks.\",\n",
    "     \"vector\": [0.3, 0.4, 0.5, 0.5]},\n",
    "    {\"content\": \"Modified prompt: Discuss optimization challenges in deep learning.\",\n",
    "     \"vector\": [0.4, 0.5, 0.6, 0.6]},\n",
    "    {\"content\": \"Modified prompt: Compare different optimization algorithms for deep learning.\",\n",
    "     \"vector\": [0.5, 0.6, 0.7, 0.7]},\n",
    "]\n",
    "\n",
    "# Measure drift\n",
    "drift_result = drift_model.measure_drift(\n",
    "    state_history=state_history,\n",
    "    reference_state=state_history[0]\n",
    ")\n",
    "\n",
    "# Display drift measurement results\n",
    "print(\"Drift Measurement Results:\")\n",
    "print(f\"Significant Drift Detected: {drift_result['significant_drift']}\")\n",
    "print(f\"Drift Type: {drift_result['drift_type'].value if hasattr(drift_result['drift_type'], 'value') else drift_result['drift_type']}\")\n",
    "print(f\"Cumulative Drift: {drift_result['metrics']['cumulative']:.4f}\")\n",
    "print(\"\\nIncremental Drifts:\")\n",
    "for i, drift in enumerate(drift_result['metrics']['incremental']):\n",
    "    print(f\"  Step {i+1}: {drift:.4f}\")\n",
    "print(f\"\\nDrift Velocity: {drift_result['metrics']['velocity']:.4f}\")\n",
    "print(f\"Drift Acceleration: {drift_result['metrics']['acceleration']:.4f}\")\n",
    "\n",
    "# Display drift analysis\n",
    "print(\"\\nDrift Analysis:\")\n",
    "print(f\"Severity: {drift_result['analysis']['severity']['level']}\")\n",
    "print(f\"Description: {drift_result['analysis']['severity']['description']}\")\n",
    "print(f\"Trajectory: {drift_result['analysis']['trajectory']['direction']}\")\n",
    "print(f\"Trend: {drift_result['analysis']['trajectory']['trend']}\")\n",
    "print(f\"Stability Projection: {drift_result['analysis']['stability_projection']['projection']}\")\n",
    "\n",
    "# Display recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in drift_result['analysis']['recommendations']:\n",
    "    print(f\"- [{rec['priority']}] {rec['type']}: {rec['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize drift over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Extract drift metrics\n",
    "incremental_drifts = [0] + drift_result['metrics']['incremental']  # Add 0 for initial state\n",
    "cumulative_drift = [0]  # Start with 0 drift\n",
    "for drift in drift_result['metrics']['incremental']:\n",
    "    cumulative_drift.append(cumulative_drift[-1] + drift)\n",
    "\n",
    "# Plot drift metrics\n",
    "plt.plot(range(len(incremental_drifts)), incremental_drifts, 'o-', label='Incremental Drift', color='blue')\n",
    "plt.plot(range(len(cumulative_drift)), cumulative_drift, 's-', label='Cumulative Drift', color='red')\n",
    "\n",
    "# Add drift threshold line\n",
    "plt.axhline(y=drift_model.parameters.drift_detection_threshold, \n",
    "           linestyle='--', color='red', alpha=0.7, label='Drift Threshold')\n",
    "\n",
    "plt.xlabel('State History Index')\n",
    "plt.ylabel('Drift Magnitude')\n",
    "plt.title('Drift Analysis Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Drift Patterns\n",
    "\n",
    "The visualization above shows how drift accumulates over time. Incremental drift measures the change between consecutive states, while cumulative drift measures the total change from the reference state.\n",
    "\n",
    "In this example, we see that:\n",
    "1. The drift gradually increases over time\n",
    "2. Eventually, the cumulative drift exceeds the drift detection threshold\n",
    "3. The system detects significant drift and provides recommendations for managing it\n",
    "\n",
    "This models how both AI and human systems can drift away from their intended behavior over time, and how monitoring and intervention can help maintain stability.\n",
    "\n",
    "Now, let's decompose the drift into intentional and unintentional components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a goal vector (intentional direction of change)\n",
    "goal_vector = np.array([0.3, 0.4, 0.5, 0.6])  # Moving toward optimization focus\n",
    "\n",
    "# Decompose drift into intentional and unintentional components\n",
    "decomposed_drift = drift_model.decompose_drift(\n",
    "    state_history=state_history,\n",
    "    goal_vector=goal_vector,\n",
    "    reference_state=state_history[0]\n",
    ")\n",
    "\n",
    "# Display decomposed drift\n",
    "print(\"Decomposed Drift:\")\n",
    "print(f\"Total Drift: {decomposed_drift['total']:.4f}\")\n",
    "print(f\"Intentional Drift: {decomposed_drift['intentional']:.4f}\")\n",
    "print(f\"Unintentional Drift: {decomposed_drift['unintentional']:.4f}\")\n",
    "print(f\"Intentional Ratio: {decomposed_drift['intentional_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize decomposed drift\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Create pie chart of intentional vs unintentional drift\n",
    "labels = ['Intentional Drift', 'Unintentional Drift']\n",
    "sizes = [decomposed_drift['intentional'], decomposed_drift['unintentional']]\n",
    "colors = ['#66b3ff', '#ff9999']\n",
    "explode = (0.1, 0)  # explode 1st slice for emphasis\n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Decomposition of Total Drift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizing Prompts with the Prompt Theory Framework\n",
    "\n",
    "Now that we've explored the core components of Prompt Theory, let's see how they come together in the PromptOptimizer class, which implements the unified optimization framework.\n",
    "\n",
    "Let's start with a basic example of prompt optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize prompt optimizer\n",
    "optimizer = PromptOptimizer(\n",
    "    model=\"gpt-4\",  # You can replace with your preferred model\n",
    "    attention_model=attention_model,\n",
    "    recursive_processor=recursive_processor,\n",
    "    drift_model=drift_model\n",
    ")\n",
    "\n",
    "# Define a base prompt to optimize\n",
    "base_prompt = \"Explain machine learning to a beginner.\"\n",
    "\n",
    "# Define task and context\n",
    "task = \"educational\"\n",
    "context = {\n",
