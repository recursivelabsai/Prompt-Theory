{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Theory: A Unified Framework\n",
    "\n",
    "This notebook provides a practical introduction to Prompt Theory, a unified framework for understanding and optimizing prompts across both AI systems and human cognition. \n",
    "\n",
    "By working through this tutorial, you'll gain hands-on experience with:\n",
    "1. The core principles of Prompt Theory\n",
    "2. Applying the mathematical framework to real-world examples\n",
    "3. Optimizing prompts using cognitive science principles\n",
    "4. Measuring and analyzing prompt effectiveness\n",
    "5. Detecting emergent behavior in recursive systems\n",
    "\n",
    "## What is Prompt Theory?\n",
    "\n",
    "Prompt Theory establishes a formal framework for understanding the structural isomorphisms between AI prompting systems and human neurobiological input-output mechanisms. By analyzing these parallel processes, we can develop more effective prompts for both AI systems and human cognition.\n",
    "\n",
    "The framework consists of three core components:\n",
    "- **Attention Allocation**: How systems focus on relevant information\n",
    "- **Recursive Processing**: How systems process information through multiple layers\n",
    "- **Drift Management**: How systems maintain stability while adapting\n",
    "\n",
    "Let's begin by installing the prompt-theory package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install prompt-theory package\n",
    "!pip install prompt-theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import core modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "from prompt_theory import PromptOptimizer\n",
    "from prompt_theory.models import AttentionModel, RecursiveProcessor, DriftModel\n",
    "from prompt_theory.evaluation import PromptEffectivenessEvaluator\n",
    "from prompt_theory.evaluation import EmergenceDetector\n",
    "from prompt_theory.optimizers import NeurobiologicalOptimizer\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Attention Allocation\n",
    "\n",
    "Attention allocation is a core component of Prompt Theory. It models how both AI systems and human cognition allocate limited attention resources across available information.\n",
    "\n",
    "The AttentionModel class implements the mathematical framework for attention allocation defined in Equation (5) of the Prompt Theory paper:\n",
    "\n",
    "$$A(X) = \\text{softmax}(Q(X) \\cdot K(X)^T / \\sqrt{d})$$\n",
    "\n",
    "With modifications for recency and salience as defined in Equation (6):\n",
    "\n",
    "$$A'(X) = \\lambda \\cdot A(X) + (1-\\lambda) \\cdot R(X)$$\n",
    "\n",
    "Let's see how this works in practice with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize attention model\n",
    "attention_model = AttentionModel(\n",
    "    capacity=7,  # Working memory-inspired capacity limit\n",
    "    recency_bias=0.3,  # Weight for recency effects\n",
    "    salience_weight=0.5  # Weight for salience factors\n",
    ")\n",
    "\n",
    "# Define a simple context with elements\n",
    "context = [\n",
    "    \"Artificial intelligence is transforming many industries.\",\n",
    "    \"Large language models are trained on vast text corpora.\",\n",
    "    \"Prompt engineering is the practice of designing effective prompts for AI systems.\",\n",
    "    \"Attention mechanisms allow models to focus on relevant parts of the input.\",\n",
    "    \"Recursive processing enables handling of complex nested structures.\",\n",
    "    \"Drift occurs when a system gradually shifts away from its intended behavior.\",\n",
    "    \"Emergence refers to the appearance of properties not predictable from components.\",\n",
    "    \"Neurobiological principles can inform AI system design.\",\n",
    "    \"Working memory is limited in capacity, typically to 7Â±2 items.\"\n",
    "]\n",
    "\n",
    "# Define salience factors (importance of each element)\n",
    "salience_factors = {\n",
    "    0: 0.5,  # General background\n",
    "    1: 0.6,  # General background\n",
    "    2: 0.9,  # Highly relevant to prompt engineering\n",
    "    3: 0.8,  # Relevant to attention mechanisms\n",
    "    4: 0.7,  # Relevant to recursive processing\n",
    "    5: 0.7,  # Relevant to drift\n",
    "    6: 0.8,  # Relevant to emergence\n",
    "    7: 0.9,  # Relevant to the neurobiological connection\n",
    "    8: 0.7   # Relevant to working memory\n",
    "}\n",
    "\n",
    "# Define recency (most recent items first)\n",
    "recency_indices = [8, 7, 6, 5, 4, 3, 2, 1, 0]  # Assuming items 8, 7, 6 were seen most recently\n",
    "\n",
    "# Allocate attention across context elements\n",
    "attention_allocation = attention_model.allocate(\n",
    "    context=context,\n",
    "    salience_factors=salience_factors,\n",
    "    recency_indices=recency_indices\n",
    ")\n",
    "\n",
    "# Display attention allocation\n",
    "for i, (element, attention) in enumerate(sorted(attention_allocation.items(), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"Element {i}: {attention:.4f} - {context[i][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize attention allocation\n",
    "plt.figure(figsize=(12, 6))\n",
    "indices = list(attention_allocation.keys())\n",
    "values = [attention_allocation[i] for i in indices]\n",
    "\n",
    "# Create shortened labels\n",
    "labels = [f\"{i}: {context[i][:30]}...\" for i in indices]\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "plt.barh(labels, values, color=sns.color_palette(\"viridis\", len(indices)))\n",
    "plt.xlabel('Attention Allocation')\n",
    "plt.ylabel('Context Elements')\n",
    "plt.title('Attention Allocation Across Context Elements')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Attention Patterns\n",
    "\n",
    "The visualization above shows how attention is distributed across the context elements based on their salience and recency. Notice that elements with high salience (relevance) and high recency receive more attention, modeling how both AI systems and human cognition prioritize information.\n",
    "\n",
    "In both domains, attention is a limited resource that must be allocated efficiently. The AttentionModel implements this constraint through the capacity parameter, which suppresses attention to less important elements when there are too many items to process.\n",
    "\n",
    "Now, let's see how we can optimize a context to focus attention on specific key elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify key elements we want to focus attention on\n",
    "key_elements = [2, 3, 7]  # Prompt engineering, attention mechanisms, and neurobiological principles\n",
    "\n",
    "# Optimize context to focus attention on these key elements\n",
    "optimized_context = attention_model.optimize_for_focus(\n",
    "    context=context,\n",
    "    target_elements=key_elements\n",
    ")\n",
    "\n",
    "# Allocate attention on the optimized context\n",
    "optimized_allocation = attention_model.allocate(\n",
    "    context=optimized_context,\n",
    "    salience_factors={i: salience_factors[optimized_context.index(context[i])] if context[i] in optimized_context else 0.5 \n",
    "                     for i in range(len(context))},\n",
    "    recency_indices=list(range(len(optimized_context)))[::-1]  # Most recent last\n",
    ")\n",
    "\n",
    "# Display optimized context\n",
    "print(\"Optimized Context:\")\n",
    "for i, element in enumerate(optimized_context):\n",
    "    print(f\"{i}: {element[:50]}...\")\n",
    "\n",
    "# Display target element attention\n",
    "print(\"\\nAttention on Target Elements:\")\n",
    "target_indices = [optimized_context.index(context[i]) for i in key_elements if context[i] in optimized_context]\n",
    "target_attention = sum(optimized_allocation.get(i, 0) for i in target_indices)\n",
    "print(f\"Total attention on target elements: {target_attention:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Recursive Processing\n",
    "\n",
    "Recursive processing is another core component of Prompt Theory. It models how systems process information through multiple layers of abstraction, and how emergence and collapse can occur during this process.\n",
    "\n",
    "The RecursiveProcessor class implements this framework, focusing on the conditions under which new properties emerge or the system becomes unstable.\n",
    "\n",
    "Let's explore a simple example of recursive processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize recursive processor\n",
    "recursive_processor = RecursiveProcessor(\n",
    "    max_depth=4,  # Maximum recursion depth\n",
    "    collapse_threshold=0.8,  # Threshold for recursive collapse\n",
    "    emergence_threshold=0.6  # Threshold for emergence\n",
    ")\n",
    "\n",
    "# Define a simple recursive processing function\n",
    "def process_recursively(state):\n",
    "    # Extract current values\n",
    "    depth = state.get(\"_depth\", 0)\n",
    "    complexity = state.get(\"complexity\", 0.2)\n",
    "    integration = state.get(\"integration\", 0.1)\n",
    "    coherence = state.get(\"coherence\", 0.9)\n",
    "    \n",
    "    # Update state based on recursive processing\n",
    "    new_state = state.copy()\n",
    "    \n",
    "    # Increase complexity with depth\n",
    "    new_state[\"complexity\"] = complexity + (0.2 * depth)\n",
    "    \n",
    "    # Increase integration (potential for emergence)\n",
    "    new_state[\"integration\"] = integration + (0.15 * depth)\n",
    "    \n",
    "    # Decrease coherence (potential for collapse) if complexity too high\n",
    "    if new_state[\"complexity\"] > 0.7:\n",
    "        new_state[\"coherence\"] = coherence - (0.1 * (new_state[\"complexity\"] - 0.7))\n",
    "    \n",
    "    # Add output at each step\n",
    "    new_state[\"_output\"] = f\"Processed at depth {depth} with complexity={new_state['complexity']:.2f}, integration={new_state['integration']:.2f}, coherence={new_state['coherence']:.2f}\"\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "# Process input recursively\n",
    "result = recursive_processor.process(\n",
    "    input_data={\"initial_data\": \"test\"},\n",
    "    processing_function=process_recursively,\n",
    "    max_iterations=10,\n",
    "    trace_execution=True\n",
    ")\n",
    "\n",
    "# Display recursive processing results\n",
    "print(\"Recursive Processing Results:\")\n",
    "print(f\"Final Output: {result['output']}\")\n",
    "print(f\"Iterations: {result['iterations']}\")\n",
    "print(f\"Depth: {result['depth']}\")\n",
    "print(f\"Converged: {result['converged']}\")\n",
    "print(f\"Stability: {result['stability']:.4f}\")\n",
    "print(f\"Emergence Detected: {result['emergence_detected']}\")\n",
    "print(f\"Collapse Detected: {result['collapse_detected']}\")\n",
    "\n",
    "# Display execution trace\n",
    "print(\"\\nExecution Trace:\")\n",
    "for i, trace_step in enumerate(result.get(\"execution_trace\", [])):\n",
    "    print(f\"Step {i}:\")\n",
    "    print(f\"  Depth: {trace_step['depth']}\")\n",
    "    print(f\"  System State: {trace_step['system_state']}\")\n",
    "    print(f\"  Discontinuity: {trace_step['discontinuity']:.4f}\")\n",
    "    print(f\"  Integration: {trace_step['integration']:.4f}\")\n",
    "    print(f\"  State: {trace_step['system_state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize recursive processing trajectory\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Extract data from execution trace\n",
    "depths = [step['depth'] for step in result.get(\"execution_trace\", [])]\n",
    "complexity = [step['state_snapshot'].get('complexity', 0) for step in result.get(\"execution_trace\", [])]\n",
    "integration = [step['integration'] for step in result.get(\"execution_trace\", [])]\n",
    "coherence = [step['state_snapshot'].get('coherence', 0) for step in result.get(\"execution_trace\", [])]\n",
    "discontinuity = [step['discontinuity'] for step in result.get(\"execution_trace\", [])]\n",
    "\n",
    "# Plot metrics\n",
    "plt.plot(depths, complexity, 'o-', label='Complexity', color='blue')\n",
    "plt.plot(depths, integration, 's-', label='Integration', color='green')\n",
    "plt.plot(depths, coherence, '^-', label='Coherence', color='purple')\n",
    "plt.plot(depths, discontinuity, 'x-', label='Discontinuity', color='red')\n",
    "\n",
    "# Add threshold lines\n",
    "plt.axhline(y=recursive_processor.parameters.emergence_threshold, \n",
    "           linestyle='--', color='green', alpha=0.7, label='Emergence Threshold')\n",
    "plt.axhline(y=recursive_processor.parameters.collapse_threshold, \n",
    "           linestyle='--', color='red', alpha=0.7, label='Collapse Threshold')\n",
    "\n",
    "plt.xlabel('Recursion Depth')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Recursive Processing Trajectory')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Recursive Processing\n",
    "\n",
    "The visualization above shows the trajectory of recursive processing. As recursion depth increases:\n",
    "\n",
    "1. **Complexity** increases, modeling the growing complexity of representations\n",
    "2. **Integration** increases, potentially leading to emergence when it exceeds the emergence threshold\n",
    "3. **Coherence** decreases as complexity increases, potentially leading to collapse when discontinuity exceeds the collapse threshold\n",
    "\n",
    "This models how both AI and human cognitive systems can develop emergent properties through recursive processing, but also risk collapse if the processing becomes too complex or incoherent.\n",
    "\n",
    "Now, let's simulate multiple recursive processing runs to analyze stability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate multiple recursive processing runs with varying noise\n",
    "simulation_results = recursive_processor.simulate_recursion(\n",
    "    input_data={\"initial_data\": \"test\"},\n",
    "    processing_function=process_recursively,\n",
    "    num_simulations=10,\n",
    "    noise_level=0.1\n",
    ")\n",
    "\n",
    "# Display simulation results\n",
    "print(\"Simulation Results:\")\n",
    "print(f\"Number of Simulations: {simulation_results['num_simulations']}\")\n",
    "print(f\"Noise Level: {simulation_results['noise_level']}\")\n",
    "print(f\"Collapse Rate: {simulation_results['collapse_rate']:.4f}\")\n",
    "print(f\"Emergence Rate: {simulation_results['emergence_rate']:.4f}\")\n",
    "print(f\"Convergence Rate: {simulation_results['convergence_rate']:.4f}\")\n",
    "print(f\"Average Iterations: {simulation_results['avg_iterations']:.2f}\")\n",
    "print(f\"Average Depth: {simulation_results['avg_depth']:.2f}\")\n",
    "print(f\"Average Stability: {simulation_results['avg_stability']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Managing Drift and Stability\n",
    "\n",
    "The third core component of Prompt Theory is drift management. It models how systems change over time and how to maintain stability while allowing for adaptation.\n",
    "\n",
    "The DriftModel class implements this framework, providing tools for measuring, predicting, and managing drift in system behavior.\n",
    "\n",
    "Let's explore a simple example of drift analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize drift model\n",
    "drift_model = DriftModel(\n",
    "    stability_params={\"anchoring_weight\": 0.7},\n",
    "    drift_detection_threshold=0.3\n",
    ")\n",
    "\n",
    "# Create a simple state history with gradually increasing drift\n",
    "state_history = [\n",
    "    {\"content\": \"Original prompt: Explain how neural networks function.\",\n",
    "     \"vector\": [0.1, 0.2, 0.3, 0.4]},\n",
    "    {\"content\": \"Modified prompt: Explain how neural networks learn from data.\",\n",
    "     \"vector\": [0.15, 0.25, 0.3, 0.4]},\n",
    "    {\"content\": \"Modified prompt: Describe neural network training and learning algorithms.\",\n",
    "     \"vector\": [0.2, 0.3, 0.35, 0.45]},\n",
    "    {\"content\": \"Modified prompt: Explain backpropagation and gradient descent in neural networks.\",\n",
    "     \"vector\": [0.3, 0.4, 0.5, 0.5]},\n",
    "    {\"content\": \"Modified prompt: Discuss optimization challenges in deep learning.\",\n",
    "     \"vector\": [0.4, 0.5, 0.6, 0.6]},\n",
    "    {\"content\": \"Modified prompt: Compare different optimization algorithms for deep learning.\",\n",
    "     \"vector\": [0.5, 0.6, 0.7, 0.7]},\n",
    "]\n",
    "\n",
    "# Measure drift\n",
    "drift_result = drift_model.measure_drift(\n",
    "    state_history=state_history,\n",
    "    reference_state=state_history[0]\n",
    ")\n",
    "\n",
    "# Display drift measurement results\n",
    "print(\"Drift Measurement Results:\")\n",
    "print(f\"Significant Drift Detected: {drift_result['significant_drift']}\")\n",
    "print(f\"Drift Type: {drift_result['drift_type'].value if hasattr(drift_result['drift_type'], 'value') else drift_result['drift_type']}\")\n",
    "print(f\"Cumulative Drift: {drift_result['metrics']['cumulative']:.4f}\")\n",
    "print(\"\\nIncremental Drifts:\")\n",
    "for i, drift in enumerate(drift_result['metrics']['incremental']):\n",
    "    print(f\"  Step {i+1}: {drift:.4f}\")\n",
    "print(f\"\\nDrift Velocity: {drift_result['metrics']['velocity']:.4f}\")\n",
    "print(f\"Drift Acceleration: {drift_result['metrics']['acceleration']:.4f}\")\n",
    "\n",
    "# Display drift analysis\n",
    "print(\"\\nDrift Analysis:\")\n",
    "print(f\"Severity: {drift_result['analysis']['severity']['level']}\")\n",
    "print(f\"Description: {drift_result['analysis']['severity']['description']}\")\n",
    "print(f\"Trajectory: {drift_result['analysis']['trajectory']['direction']}\")\n",
    "print(f\"Trend: {drift_result['analysis']['trajectory']['trend']}\")\n",
    "print(f\"Stability Projection: {drift_result['analysis']['stability_projection']['projection']}\")\n",
    "\n",
    "# Display recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in drift_result['analysis']['recommendations']:\n",
    "    print(f\"- [{rec['priority']}] {rec['type']}: {rec['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize drift over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Extract drift metrics\n",
    "incremental_drifts = [0] + drift_result['metrics']['incremental']  # Add 0 for initial state\n",
    "cumulative_drift = [0]  # Start with 0 drift\n",
    "for drift in drift_result['metrics']['incremental']:\n",
    "    cumulative_drift.append(cumulative_drift[-1] + drift)\n",
    "\n",
    "# Plot drift metrics\n",
    "plt.plot(range(len(incremental_drifts)), incremental_drifts, 'o-', label='Incremental Drift', color='blue')\n",
    "plt.plot(range(len(cumulative_drift)), cumulative_drift, 's-', label='Cumulative Drift', color='red')\n",
    "\n",
    "# Add drift threshold line\n",
    "plt.axhline(y=drift_model.parameters.drift_detection_threshold, \n",
    "           linestyle='--', color='red', alpha=0.7, label='Drift Threshold')\n",
    "\n",
    "plt.xlabel('State History Index')\n",
    "plt.ylabel('Drift Magnitude')\n",
    "plt.title('Drift Analysis Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Drift Patterns\n",
    "\n",
    "The visualization above shows how drift accumulates over time. Incremental drift measures the change between consecutive states, while cumulative drift measures the total change from the reference state.\n",
    "\n",
    "In this example, we see that:\n",
    "1. The drift gradually increases over time\n",
    "2. Eventually, the cumulative drift exceeds the drift detection threshold\n",
    "3. The system detects significant drift and provides recommendations for managing it\n",
    "\n",
    "This models how both AI and human systems can drift away from their intended behavior over time, and how monitoring and intervention can help maintain stability.\n",
    "\n",
    "Now, let's decompose the drift into intentional and unintentional components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a goal vector (intentional direction of change)\n",
    "goal_vector = np.array([0.3, 0.4, 0.5, 0.6])  # Moving toward optimization focus\n",
    "\n",
    "# Decompose drift into intentional and unintentional components\n",
    "decomposed_drift = drift_model.decompose_drift(\n",
    "    state_history=state_history,\n",
    "    goal_vector=goal_vector,\n",
    "    reference_state=state_history[0]\n",
    ")\n",
    "\n",
    "# Display decomposed drift\n",
    "print(\"Decomposed Drift:\")\n",
    "print(f\"Total Drift: {decomposed_drift['total']:.4f}\")\n",
    "print(f\"Intentional Drift: {decomposed_drift['intentional']:.4f}\")\n",
    "print(f\"Unintentional Drift: {decomposed_drift['unintentional']:.4f}\")\n",
    "print(f\"Intentional Ratio: {decomposed_drift['intentional_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize decomposed drift\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Create pie chart of intentional vs unintentional drift\n",
    "labels = ['Intentional Drift', 'Unintentional Drift']\n",
    "sizes = [decomposed_drift['intentional'], decomposed_drift['unintentional']]\n",
    "colors = ['#66b3ff', '#ff9999']\n",
    "explode = (0.1, 0)  # explode 1st slice for emphasis\n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Decomposition of Total Drift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizing Prompts with the Prompt Theory Framework\n",
    "\n",
    "Now that we've explored the core components of Prompt Theory, let's see how they come together in the PromptOptimizer class, which implements the unified optimization framework.\n",
    "\n",
    "Let's start with a basic example of prompt optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize prompt optimizer\n",
    "optimizer = PromptOptimizer(\n",
    "    model=\"gpt-4\",  # You can replace with your preferred model\n",
    "    attention_model=attention_model,\n",
    "    recursive_processor=recursive_processor,\n",
    "    drift_model=drift_model\n",
    ")\n",
    "\n",
    "# Define a base prompt to optimize\n",
    "base_prompt = \"Explain machine learning to a beginner.\"\n",
    "\n",
    "# Define task and context\n",
    "task = \"educational\"\n",
    "context = {\n",
    "    \"audience\": \"beginner\
  {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize prompt optimizer\n",
    "optimizer = PromptOptimizer(\n",
    "    model=\"gpt-4\",  # You can replace with your preferred model\n",
    "    attention_model=attention_model,\n",
    "    recursive_processor=recursive_processor,\n",
    "    drift_model=drift_model\n",
    ")\n",
    "\n",
    "# Define a base prompt to optimize\n",
    "base_prompt = \"Explain machine learning to a beginner.\"\n",
    "\n",
    "# Define task and context\n",
    "task = \"educational\"\n",
    "context = {\n",
    "    \"audience\": \"beginner\",\n",
    "    \"domain\": \"machine_learning\",\n",
    "    \"prior_knowledge\": \"basic computer knowledge\",\n",
    "    \"learning_objectives\": [\"understand basic concepts\", \"grasp key techniques\", \"recognize applications\"]\n",
    "}\n",
    "\n",
    "# Define constraints\n",
    "constraints = {\n",
    "    \"max_tokens\": 500,\n",
    "    \"audience\": \"beginner\",\n",
    "    \"style\": \"conversational\"\n",
    "}\n",
    "\n",
    "# Optimize the prompt\n",
    "optimized_prompt = optimizer.optimize(\n",
    "    base_prompt=base_prompt,\n",
    "    task=task,\n",
    "    context=context,\n",
    "    constraints=constraints,\n",
    "    trace_optimization=True\n",
    ")\n",
    "\n",
    "# Display the optimized prompt\n",
    "print(\"Base Prompt:\")\n",
    "print(base_prompt)\n",
    "print(\"\\nOptimized Prompt:\")\n",
    "print(optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized prompt demonstrates several key Prompt Theory principles:\n",
    "\n",
    "1. **Attention Guidance**: Directing focus to key concepts through structural elements\n",
    "2. **Working Memory Management**: Breaking information into manageable chunks\n",
    "3. **Recursive Structure**: Building complexity gradually through layered explanations\n",
    "4. **Drift Prevention**: Maintaining alignment with the original task while adapting to context\n",
    "\n",
    "Now, let's evaluate the effectiveness of our optimized prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize effectiveness evaluator\n",
    "evaluator = PromptEffectivenessEvaluator()\n",
    "\n",
    "# Evaluate base prompt\n",
    "base_effectiveness = evaluator.evaluate(\n",
    "    prompt=base_prompt,\n",
    "    task=task,\n",
    "    context=context,\n",
    "    detailed_scores=True\n",
    ")\n",
    "\n",
    "# Evaluate optimized prompt\n",
    "optimized_effectiveness = evaluator.evaluate(\n",
    "    prompt=optimized_prompt,\n",
    "    task=task,\n",
    "    context=context,\n",
    "    detailed_scores=True\n",
    ")\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Base Prompt Effectiveness:\")\n",
    "print(f\"Overall Score: {base_effectiveness['overall_effectiveness']:.4f}\")\n",
    "print(\"Component Scores:\")\n",
    "for component, score in base_effectiveness['component_scores'].items():\n",
    "    print(f\"  {component}: {score:.4f}\")\n",
    "print(\"\\nOptimized Prompt Effectiveness:\")\n",
    "print(f\"Overall Score: {optimized_effectiveness['overall_effectiveness']:.4f}\")\n",
    "print(\"Component Scores:\")\n",
    "for component, score in optimized_effectiveness['component_scores'].items():\n",
    "    print(f\"  {component}: {score:.4f}\")\n",
    "print(\"\\nImprovement:\")\n",
    "improvement = optimized_effectiveness['overall_effectiveness'] - base_effectiveness['overall_effectiveness']\n",
    "print(f\"Overall Improvement: {improvement:.4f} ({improvement*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize effectiveness comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Extract component scores\n",
    "components = list(base_effectiveness['component_scores'].keys())\n",
    "base_scores = [base_effectiveness['component_scores'][c] for c in components]\n",
    "optimized_scores = [optimized_effectiveness['component_scores'][c] for c in components]\n",
    "\n",
    "# Add overall effectiveness\n",
    "components.append('overall_effectiveness')\n",
    "base_scores.append(base_effectiveness['overall_effectiveness'])\n",
    "optimized_scores.append(optimized_effectiveness['overall_effectiveness'])\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(components))\n",
    "width = 0.35\n",
    "\n",
    "# Create grouped bar chart\n",
    "plt.bar(x - width/2, base_scores, width, label='Base Prompt', color='#5c7cfa')\n",
    "plt.bar(x + width/2, optimized_scores, width, label='Optimized Prompt', color='#51cf66')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Effectiveness Components')\n",
    "plt.ylabel('Score (0-1)')\n",
    "plt.title('Prompt Effectiveness Comparison')\n",
    "plt.xticks(x, [c.replace('_', ' ').title() for c in components], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Add grid and adjust layout\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detecting Emergence in Recursive Systems\n",
    "\n",
    "Finally, let's explore the EmergenceDetector class, which implements the framework for detecting and characterizing emergent properties in recursive systems.\n",
    "\n",
    "This is particularly important for understanding how complex behaviors and capabilities can emerge in both AI and human cognitive systems through recursive processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize emergence detector\n",
    "emergence_detector = EmergenceDetector(\n",
    "    recursive_processor=recursive_processor,\n",
    "    emergence_threshold=0.6,\n",
    "    integration_threshold=0.7\n",
    ")\n",
    "\n",
    "# Create a state history with potential emergent properties\n",
    "emergence_state_history = [\n",
    "    {\"iteration\": 0, \"complexity\": 0.2, \"integration\": 0.1, \"discontinuity\": 0.1},\n",
    "    {\"iteration\": 1, \"complexity\": 0.3, \"integration\": 0.2, \"discontinuity\": 0.15},\n",
    "    {\"iteration\": 2, \"complexity\": 0.4, \"integration\": 0.35, \"discontinuity\": 0.2},\n",
    "    {\"iteration\": 3, \"complexity\": 0.5, \"integration\": 0.5, \"discontinuity\": 0.25},\n",
    "    {\"iteration\": 4, \"complexity\": 0.6, \"integration\": 0.65, \"discontinuity\": 0.3},\n",
    "    {\"iteration\": 5, \"complexity\": 0.7, \"integration\": 0.75, \"discontinuity\": 0.4}\n",
    "]\n",
    "\n",
    "# Detect emergence\n",
    "emergence_result = emergence_detector.detect_emergence(\n",
    "    state_history=emergence_state_history,\n",
    "    analysis_depth=\"standard\",\n",
    "    detect_type=True\n",
    ")\n",
    "\n",
    "# Display emergence detection results\n",
    "print(\"Emergence Detection Results:\")\n",
    "print(f\"Emergence Detected: {emergence_result['emergence_detected']}\")\n",
    "print(f\"Confidence: {emergence_result['confidence']:.4f}\")\n",
    "if emergence_result['emergence_detected']:\n",
    "    print(f\"Emergence Type: {emergence_result['emergence_type']}\")\n",
    "    print(f\"Type Confidence: {emergence_result['type_confidence']:.4f}\")\n",
    "    print(\"\\nEvidence:\")\n",
    "    for evidence in emergence_result['type_evidence']:\n",
    "        print(f\"  - {evidence['description']} (Confidence: {evidence['confidence']:.4f})\")\n",
    "    \n",
    "    if 'pattern_analysis' in emergence_result:\n",
    "        print(\"\\nPattern Analysis:\")\n",
    "        print(f\"  Emergence Trajectory: {emergence_result['pattern_analysis']['emergence_trajectory']}\")\n",
    "        print(f\"  Stability: {emergence_result['pattern_analysis']['stability']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize emergence detection\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Extract data from state history\n",
    "iterations = [state[\"iteration\"] for state in emergence_state_history]\n",
    "complexity = [state[\"complexity\"] for state in emergence_state_history]\n",
    "integration = [state[\"integration\"] for state in emergence_state_history]\n",
    "discontinuity = [state[\"discontinuity\"] for state in emergence_state_history]\n",
    "\n",
    "# Plot metrics\n",
    "plt.plot(iterations, complexity, 'o-', label='Complexity', color='blue')\n",
    "plt.plot(iterations, integration, 's-', label='Integration', color='green')\n",
    "plt.plot(iterations, discontinuity, 'x-', label='Discontinuity', color='red')\n",
    "\n",
    "# Add threshold lines\n",
    "plt.axhline(y=emergence_detector.emergence_threshold, \n",
    "           linestyle='--', color='green', alpha=0.7, label='Emergence Threshold')\n",
    "plt.axhline(y=recursive_processor.parameters.collapse_threshold, \n",
    "           linestyle='--', color='red', alpha=0.7, label='Collapse Threshold')\n",
    "\n",
    "# Highlight emergence point if detected\n",
    "if emergence_result['emergence_detected']:\n",
    "    # Find first point where integration exceeds threshold\n",
    "    emergence_idx = next((i for i, val in enumerate(integration) if val > emergence_detector.emergence_threshold), -1)\n",
    "    if emergence_idx >= 0:\n",
    "        plt.scatter([iterations[emergence_idx]], [integration[emergence_idx]], \n",
    "                   s=200, facecolors='none', edgecolors='green', linewidths=2,\n",
    "                   label='Emergence Point')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Emergence Detection Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterizing Emergence\n",
    "\n",
    "When emergence is detected, we can use the EmergenceDetector to characterize it in more detail, providing insights into its properties, implications, and recommendations for system management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Characterize emergence\n",
    "if emergence_result['emergence_detected']:\n",
    "    characterization = emergence_detector.characterize_emergence(\n",
    "        emergence_result=emergence_result,\n",
    "        state_history=emergence_state_history,\n",
    "        context={\"domain\": \"cognitive_system\", \"task\": \"learning\"}\n",
    "    )\n",
    "    \n",
    "    # Display characterization\n",
    "    print(\"Emergence Characterization:\")\n",
    "    print(f\"Description: {characterization['description']}\")\n",
    "    print(\"\\nProperties:\")\n",
    "    for prop, value in characterization['properties'].items():\n",
    "        print(f\"  {prop}: {value}\")\n",
    "    print(\"\\nImplications:\")\n",
    "    for imp in characterization['implications']:\n",
    "        print(f\"  - {imp}\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in characterization['recommendations']:\n",
    "        print(f\"  - {rec}\")\n",
    "else:\n",
    "    print(\"No emergence detected to characterize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using the Neurobiological Optimizer\n",
    "\n",
    "The NeurobiologicalOptimizer extends the base PromptOptimizer with specialized optimization techniques inspired by human cognitive processes. Let's see how it works in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize neurobiological optimizer\n",
    "neuro_optimizer = NeurobiologicalOptimizer(\n",
    "    model=\"gpt-4\",\n",
    "    cognitive_parameters={\n",
    "        \"working_memory\": {\n",
    "            \"capacity\": 5,  # Reduced for novice audience\n",
    "            \"chunk_size\": 3,\n",
    "            \"decay_rate\": 0.1,\n",
    "        },\n",
    "        \"attention\": {\n",
    "            \"sustained_duration\": 15,  # Seconds of sustained attention\n",
    "            \"context_switch_cost\": 0.2,\n",
    "            \"salience_threshold\": 0.3,\n",
    "        },\n",
    "        \"processing\": {\n",
    "            \"cognitive_load_threshold\": 0.6,  # Lower for novice audience\n",
    "            \"processing_speed_factor\": 0.8,\n",
    "            \"interference_sensitivity\": 0.4,\n",
    "        },\n",
    "    },\n",
    "    attention_model=attention_model,\n",
    "    recursive_processor=recursive_processor,\n",
    "    drift_model=drift_model\n",
    ")\n",
    "\n",
    "# Define a complex concept to explain\n",
    "complex_prompt = \"Explain how neural networks learn through backpropagation.\"\n",
    "\n",
    "# Define neurobiological optimization context\n",
    "neuro_context = {\n",
    "    \"audience\": \"high_school_student\",\n",
    "    \"domain\": \"machine_learning\",\n",
    "    \"prior_knowledge\": [\"basic algebra\", \"simple statistics\"],\n",
    "    \"learning_objectives\": [\"understand gradient descent\", \"grasp neural network training\"]\n",
    "}\n",
    "\n",
    "# Optimize using neurobiological principles\n",
    "neuro_optimized_prompt = neuro_optimizer.optimize(\n",
    "    base_prompt=complex_prompt,\n",
    "    task=\"educational\",\n",
    "    context=neuro_context,\n",
    "    cognitive_profile=\"novice\",  # Apply novice cognitive profile\n",
    "    trace_optimization=True\n",
    ")\n",
    "\n",
    "# Display the neurobiologically optimized prompt\n",
    "print(\"Complex Prompt:\")\n",
    "print(complex_prompt)\n",
    "print(\"\\nNeurobiologically Optimized Prompt:\")\n",
    "print(neuro_optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurobiologically optimized prompt demonstrates additional cognitive science principles:\n",
    "\n",
    "1. **Working Memory Optimization**: Structured to respect the limited working memory capacity of novice learners\n",
    "2. **Chunking**: Information grouped into manageable chunks to aid comprehension and retention\n",
    "3. **Cognitive Load Management**: Complexity reduced to stay below the cognitive load threshold\n",
    "4. **Attention Guidance**: Visual and structural elements to guide attention to key concepts\n",
    "5. **Metacognitive Scaffolding**: Explicit prompts for reflection and self-monitoring\n",
    "\n",
    "These principles ensure that the prompt is optimized not just for AI systems, but for human cognitive processing as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored the core components of Prompt Theory and seen how they can be applied to optimize prompts for both AI systems and human cognition. We've demonstrated:\n",
    "\n",
    "1. **Attention Allocation**: How systems focus on relevant information and how we can optimize this process\n",
    "2. **Recursive Processing**: How systems process information through multiple layers and how emergence and collapse can occur\n",
    "3. **Drift Management**: How systems change over time and how to maintain stability while allowing for adaptation\n",
    "4. **Prompt Optimization**: How these components come together in a unified optimization framework\n",
    "5. **Emergence Detection**: How to identify and characterize emergent properties in recursive systems\n",
    "6. **Neurobiological Optimization**: How to apply cognitive science principles to prompt design\n",
    "\n",
    "Prompt Theory provides a powerful framework for understanding and optimizing the interface between humans and AI systems, with applications across education, research, clinical settings, and many other domains.\n",
    "\n",
    "For more information, refer to the [Prompt Theory documentation](https://prompt-theory.readthedocs.io/) and [GitHub repository](https://github.com/recursivelabs/prompt-theory)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
